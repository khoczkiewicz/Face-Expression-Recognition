{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on:\n",
    "# https://pythonhosted.org/scikit-fuzzy/auto_examples/plot_tipping_problem_newapi.html\n",
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "\n",
    "# New Antecedent/Consequent objects hold universe variables and membership\n",
    "# functions\n",
    "smile = ctrl.Antecedent(np.arange(0, 1, 0.1), 'smile')\n",
    "eyebrows = ctrl.Antecedent(np.arange(0, 1, 0.1), 'eyebrows')\n",
    "mouth = ctrl.Antecedent(np.arange(0, 1, 0.1), 'mouth')\n",
    "emotion = ctrl.Consequent(np.arange(0, 30, 1), 'emotion')\n",
    "\n",
    "# Auto-membership function population is possible with .automf(3, 5, or 7)\n",
    "smile.automf(3)\n",
    "eyebrows.automf(3)\n",
    "mouth.automf(3)\n",
    "\n",
    "# Custom membership functions can be built interactively with a familiar,\n",
    "# Pythonic API\n",
    "emotion['anger'] = fuzz.trimf(emotion.universe, [0, 0, 5])\n",
    "emotion['fear'] = fuzz.trimf(emotion.universe, [0, 5, 10])\n",
    "emotion['disgust'] = fuzz.trimf(emotion.universe, [5, 10, 15])\n",
    "emotion['sadness'] = fuzz.trimf(emotion.universe, [10, 15, 20])\n",
    "emotion['natural'] = fuzz.trimf(emotion.universe, [15, 20, 25])\n",
    "emotion['happiness'] = fuzz.trimf(emotion.universe, [20, 25, 25])\n",
    "\n",
    "# You can see how these look with .view()\n",
    "#smile['average'].view()\n",
    "#eyebrows['average'].view()\n",
    "#mouth['average'].view()\n",
    "#emotion['normal'].view()\n",
    "\n",
    "rule1 = ctrl.Rule(eyebrows['poor'] & mouth['poor'], emotion['anger'])\n",
    "rule2 = ctrl.Rule(eyebrows['poor'] & mouth['good'], emotion['fear'])\n",
    "rule3 = ctrl.Rule(mouth['good'], emotion['disgust'])\n",
    "rule4 = ctrl.Rule(eyebrows['poor'] & smile['poor'], emotion['sadness'])\n",
    "rule5 = ctrl.Rule(eyebrows['average'] & smile['average'] & mouth['average'], emotion['natural'])\n",
    "rule6 = ctrl.Rule(smile['good'], emotion['happiness'])\n",
    "\n",
    "rule1.view()\n",
    "\n",
    "expression_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5, rule6])\n",
    "\n",
    "expression = ctrl.ControlSystemSimulation(expression_ctrl)\n",
    "\n",
    "# Pass inputs to the ControlSystem using Antecedent labels with Pythonic API\n",
    "# Note: if you like passing many inputs all at once, use .inputs(dict_of_data)\n",
    "expression.input['eyebrows'] = 0.5\n",
    "expression.input['mouth'] = 0.5\n",
    "expression.input['smile'] = 0.5\n",
    "\n",
    "# Crunch the numbers\n",
    "expression.compute()\n",
    "\n",
    "#print(expression.output['emotion'])\n",
    "emotion.view(sim=expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on:\n",
    "# https://www.geeksforgeeks.org/python-smile-detection-using-opencv/\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_smile.xml\")\n",
    "\n",
    "#happy_mask = cv2.imread(\"testMask.png\",  cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect(gray, frame):\n",
    "    smile = False\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        #cv2.rectangle(frame, (x, y), ((x + w), (y + h)), (255, 0, 0), 2) #rysuje prostokąt na obrazie oryginalnym - zaznaczenie twarzy\n",
    "        #cv2.rectangle(gray, (x, y), ((x + w), (y + h)), (255, 0, 0), 2) #rysuje prostokąt na obrazie szarym - zaznaczenie twarzy\n",
    "        roi_gray = gray[y:y + h, x:x + w]# położenie twarzy na szarym\n",
    "        roi_color = frame[y:y + h, x:x + w]# położenie twarzy na oryginalnym\n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, 1.8, 20)\n",
    "\n",
    "        for (sx, sy, sw, sh) in smiles:\n",
    "            \n",
    "            #cv2.rectangle(roi_color, (sx, sy), ((sx + sw), (sy + sh)), (0, 0, 255), 2)#-||- zaznaczenie uśmiechu\n",
    "            #cv2.rectangle(roi_gray, (sx, sy), ((sx + sw), (sy + sh)), (0, 0, 255), 2)#-||- szarym zaznaczenie uśmiechu\n",
    "            #happy_mask_r = cv2.resize(happy_mask, (w, h))\n",
    "            #frame = overlay_transparent(frame, happy_mask_r, x, y)\n",
    "        \n",
    "            smile = True\n",
    "            \n",
    "    #return frame, gray\n",
    "    return smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Face landmarks lib\n",
    "import dlib\n",
    "\n",
    "# Screen capturing libs and defs\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "\n",
    "sct = mss()\n",
    "mon = {'top': 450, 'left': 720, 'width': 500, 'height': 500}\n",
    "\n",
    "# Face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Landmark identifier. Set the filename to whatever you named the downloaded file\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "#img = cv2.imread('tim_roth_images/7173390615_foto-v-pol-lica.jpg')\n",
    "\n",
    "# Main frame ~ excluded by screen capturing\n",
    "#frame = np.array(img)\n",
    "    \n",
    "# To capture image in monochrome\n",
    "#gray = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n",
    "\n",
    "#clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "#clahe_image = clahe.apply(gray)\n",
    "\n",
    "#Detect the faces in the image\n",
    "#detections = detector(clahe_image, 1)\n",
    "\n",
    "# 1-16 jaw\n",
    "# 17-21 left eyebrow\n",
    "leftPartOfLeftEyebrow = 17\n",
    "rightPartOfLeftEyebrow = 21\n",
    "\n",
    "# 22-26 right eyebrow\n",
    "leftPartOfRightEyebrow = 26\n",
    "rightPartOfRightEyebrow = 22\n",
    "\n",
    "# 27-35 nose\n",
    "# 36-41 left eye\n",
    "# 42-47 right eye\n",
    "\n",
    "# 48-68 mouth\n",
    "# upperUpLip 50-52\n",
    "upperUpLip = 51\n",
    "\n",
    "# upperDownLip 61-63\n",
    "upperDownLip = 62\n",
    "            \n",
    "# lowerLowLip 56-58\n",
    "lowerLowLip = 57\n",
    "\n",
    "# lowerUpLip 65-68\n",
    "lowerUpLip = 66\n",
    "\n",
    "# mouth corners\n",
    "leftMouthCorner = 48\n",
    "rightMouthCorner = 54\n",
    "\n",
    "maxMarksRange = 68\n",
    "\n",
    "# cv2 putText Settings\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.7\n",
    "fontColor = (255,255,0)\n",
    "lineType = 2\n",
    "\n",
    "smile = False;\n",
    "\n",
    "while 1:\n",
    "    sct.get_pixels(mon)\n",
    "    img = Image.frombytes('RGB', (sct.width, sct.height), sct.image)\n",
    "    \n",
    "    frame = np.array(img)\n",
    "    \n",
    "    # To capture image in monochrome\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGBA2GRAY)\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_image = clahe.apply(gray)\n",
    "\n",
    "    #Detect the faces in the image\n",
    "    detections = detector(clahe_image, 1)\n",
    "    \n",
    "    smile = detect(gray, frame)\n",
    "    \n",
    "    # Main loop for each detected face\n",
    "    for k,d in enumerate(detections):\n",
    "\n",
    "        xlist = []\n",
    "        ylist = []\n",
    "\n",
    "        #print(\"Face \",k)\n",
    "        #print(\"Position: \", d)\n",
    "\n",
    "        #Get coordinates\n",
    "        shape = predictor(clahe_image, d)\n",
    "\n",
    "        #print(\"Coordinates: \")\n",
    "        for i in range(leftPartOfLeftEyebrow, leftPartOfRightEyebrow + 1):\n",
    "\n",
    "            # First set to identify center of gravity\n",
    "            xlist.append(float(shape.part(i).x))\n",
    "            ylist.append(float(shape.part(i).y))\n",
    "\n",
    "            # Eyebrows marks\n",
    "            cv2.circle(frame, (shape.part(i).x, shape.part(i).y), 1, (0,0,255), thickness=2)\n",
    "            #print(\"[\", i, \"]: \", shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "        # Eyebrows down\n",
    "        if shape.part(leftPartOfLeftEyebrow).y < shape.part(rightPartOfLeftEyebrow).y or shape.part(leftPartOfRightEyebrow).y < shape.part(rightPartOfRightEyebrow).y:\n",
    "            cv2.putText(frame,'opuszczone brwi', (shape.part(rightPartOfLeftEyebrow).x, shape.part(rightPartOfLeftEyebrow).y),\n",
    "                        font, fontScale, fontColor, lineType)\n",
    "\n",
    "            expression.input['eyebrows'] = 0\n",
    "        else:\n",
    "            expression.input['eyebrows'] = 0.5\n",
    "\n",
    "        # Mouth drawings\n",
    "        for i in range(leftMouthCorner, maxMarksRange):\n",
    "            cv2.circle(frame, (shape.part(i).x, shape.part(i).y), 1, (0,0,255), thickness=2)\n",
    "\n",
    "            # Second set to identify center of gravity\n",
    "            xlist.append(float(shape.part(i).x))\n",
    "            ylist.append(float(shape.part(i).y))\n",
    "\n",
    "        # Calls the haarcascade's detect() function\n",
    "        if(smile):\n",
    "                cv2.putText(frame,'usmiech', (shape.part(lowerUpLip).x, shape.part(lowerUpLip).y), font, fontScale, fontColor, lineType)\n",
    "                expression.input['smile'] = 1\n",
    "                expression.input['mouth'] = 0.5\n",
    "        \n",
    "        else:\n",
    "            expression.input['smile'] = 0.5\n",
    "\n",
    "            # Mouth specs\n",
    "            # Pursed lips\n",
    "            if not (shape.part(lowerLowLip).y - shape.part(lowerUpLip).y)/2 < shape.part(lowerUpLip).y - shape.part(upperUpLip).y:\n",
    "                cv2.putText(frame,'zacisniete usta', (shape.part(lowerUpLip).x, shape.part(lowerUpLip).y), font, fontScale, fontColor, lineType)\n",
    "                expression.input['mouth'] = 0\n",
    "            else:\n",
    "                # Open mouth\n",
    "                medUpperLipY = (shape.part(upperDownLip).y + shape.part(upperUpLip).y)/2\n",
    "                if shape.part(rightMouthCorner).y > medUpperLipY and shape.part(leftMouthCorner).y > medUpperLipY:\n",
    "                    cv2.putText(frame,'otwarte usta', (shape.part(lowerUpLip).x, shape.part(lowerUpLip).y), font, fontScale, fontColor, lineType)\n",
    "                    expression.input['mouth'] = 1\n",
    "                else:\n",
    "                    expression.input['mouth'] = 0.5\n",
    "\n",
    "        # Lips marks\n",
    "        cv2.circle(frame, (shape.part(lowerUpLip).x, shape.part(lowerUpLip).y), 1, (0,0,255), thickness=2)\n",
    "        cv2.circle(frame, (shape.part(lowerLowLip).x, shape.part(lowerLowLip).y), 1, (0,0,255), thickness=2)\n",
    "        cv2.circle(frame, (shape.part(upperUpLip).x, shape.part(upperUpLip).y), 1, (0,255,255), thickness=2)\n",
    "        cv2.circle(frame, (shape.part(upperDownLip).x, shape.part(upperDownLip).y), 1, (0,255,255), thickness=2)\n",
    "\n",
    "        # Lips corners marks\n",
    "        cv2.circle(frame, (shape.part(leftMouthCorner).x, shape.part(leftMouthCorner).y), 1, (255,255,255), thickness=2)\n",
    "        cv2.circle(frame, (shape.part(rightMouthCorner).x, shape.part(rightMouthCorner).y), 1, (255,255,255), thickness=2)\n",
    "\n",
    "        # Find both coordinates of centre of gravity\n",
    "        xmean = np.mean(xlist) \n",
    "        ymean = np.mean(ylist)\n",
    "\n",
    "        # Draw lines between marks and center of gravity\n",
    "        #for i in range(leftPartOfLeftEyebrow, maxMarksRange):\n",
    "            #cv2.line(frame, (shape.part(i).x, shape.part(i).y), (int(xmean), int(ymean)), (0,255,0), 1)\n",
    "\n",
    "        # Draw center of gravity\n",
    "        cv2.circle(frame, (int(xmean), int(ymean)), 1, (255,0,0), thickness=2)\n",
    "\n",
    "        # Crunch the numbers to fuzzy system\n",
    "        expression.compute()\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"image\", frame)\n",
    "\n",
    "    # Exit program when the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        \n",
    "        # Show plot for specific emotion and print unique value\n",
    "        print(\"TRC: \", expression.output['emotion'])\n",
    "        emotion.view(sim=expression)\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
